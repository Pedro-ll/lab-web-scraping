{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended content.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit the urls below and take a look at their source code through Chrome DevTools. You'll need to identify the html tags, special class names, etc used in the html content you are expected to extract.\n",
    "\n",
    "**Resources**:\n",
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide)\n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are already imported for you. If you prefer to use additional libraries feel free to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "response=requests.get(url)\n",
    "\n",
    "#response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools or clicking in 'Inspect' on any browser. Here is an example:\n",
    "\n",
    "![title](example_1.png)\n",
    "\n",
    "2. Use BeautifulSoup `find_all()` to extract all the html elements that contain the developer names. Hint: pass in the `attrs` parameter to specify the class.\n",
    "\n",
    "3. Loop through the elements found and get the text for each of them.\n",
    "\n",
    "4. While you are at it, use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names. Hint: you may also use `.get_text()` instead of `.text` and pass in the desired parameters to do some string manipulation (check the documentation).\n",
    "\n",
    "5. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Benoît Grélard (benoitgrelard)',\n",
       " 'Jason Quense (jquense)',\n",
       " 'Brad Fitzpatrick (bradfitz)',\n",
       " 'Agniva De Sarker (agnivade)',\n",
       " '@greweb (gre)',\n",
       " 'Máximo Mussini (ElMassimo)',\n",
       " 'Ryan Bates (ryanb)',\n",
       " 'Leigh McCulloch (leighmcculloch)',\n",
       " 'Joe Previte (jsjoeio)',\n",
       " 'Tianon Gravi (tianon)',\n",
       " 'Klaus Post (klauspost)',\n",
       " 'Gao Sun (gao-sun)',\n",
       " 'Payton Swick (sirbrillig)',\n",
       " 'Victor Eke (Evavic44)',\n",
       " 'David Sherret (dsherret)',\n",
       " 'Kevin Wang (thiskevinwang)',\n",
       " 'Damian Edwards (DamianEdwards)',\n",
       " 'Mark Dalgleish (markdalgleish)',\n",
       " 'Tim Besard (maleadt)',\n",
       " 'Mathias Fredriksson (mafredri)',\n",
       " 'Steve Sewell (steve8708)',\n",
       " 'Seth Vargo (sethvargo)',\n",
       " 'Hari Sekhon (HariSekhon)',\n",
       " 'Lucas Bustamante (Luc45)',\n",
       " 'Diego Muracciole (diegomura)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "soup=BeautifulSoup(response.content)\n",
    "\n",
    "data_name=soup.find_all(\"h1\",attrs={\"class\":\"h3 lh-condensed\"})\n",
    "\n",
    "data_tag=soup.find_all(\"p\",attrs={\"class\":\"f4 text-normal mb-1\"})\n",
    "\n",
    "lista_name_tag=[]\n",
    "\n",
    "\n",
    "for i in range(0,len(data_name)):\n",
    "    lista_name_tag.append(data_name[i].text.strip()+\" (\"+data_tag[i].text.strip()+\")\")\n",
    "\n",
    "\n",
    "lista_name_tag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Display the trending Python repositories in GitHub.\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "response=requests.get(url=url)\n",
    "\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chip-red-pill',\n",
       " 'NVIDIA',\n",
       " 'charlax',\n",
       " 'microsoft',\n",
       " 'kraanzu',\n",
       " 'hkchengrex',\n",
       " 'open-mmlab',\n",
       " 'commaai',\n",
       " 'pytorch',\n",
       " 'keras-team',\n",
       " 'manoss96',\n",
       " 'NVlabs',\n",
       " 'yzhao062',\n",
       " 'localstack',\n",
       " 'optuna',\n",
       " 'aaugustin',\n",
       " 'splunk',\n",
       " 'quantumlib',\n",
       " 'SilentNightSound',\n",
       " 'facebookresearch',\n",
       " 'fslongjin',\n",
       " 'Asabeneh',\n",
       " 'open-mmlab',\n",
       " 'open-mmlab',\n",
       " 'joaomaranhao']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup=BeautifulSoup(response.content)\n",
    "\n",
    "data=soup.find_all(\"span\",attrs={\"class\":\"text-normal\"})\n",
    "\n",
    "repos=[]\n",
    "\n",
    "for element in data:\n",
    "    repos.append(element.text.replace(\"/\",\"\").strip())\n",
    "\n",
    "\n",
    "repos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Display all the image links from Walt Disney wikipedia page.\n",
    "Hint: use `.get()` to access information inside tags. Check out the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['//upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/8/8c/Extended-protection-shackle.svg/20px-Extended-protection-shackle.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/8/87/Walt_Disney_1942_signature.svg/150px-Walt_Disney_1942_signature.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/220px-Walt_Disney_envelope_ca._1921.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Trolley_Troubles_poster.jpg/170px-Trolley_Troubles_poster.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/4/4e/Steamboat-willie.jpg/170px-Steamboat-willie.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/5/57/Walt_Disney_1935.jpg/170px-Walt_Disney_1935.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/220px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/170px-Disney_drawing_goofy.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/220px-DisneySchiphol1951.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/220px-WaltDisneyplansDisneylandDec1954.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/170px-Walt_disney_portrait_right.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Walt_Disney_Grave.JPG/170px-Walt_Disney_Grave.JPG',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Roy_O._Disney_with_Company_at_Press_Conference.jpg/170px-Roy_O._Disney_with_Company_at_Press_Conference.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Disney_Oscar_1953_%28cropped%29.jpg/170px-Disney_Oscar_1953_%28cropped%29.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/170px-Disney1968.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/e/e3/Disneyland_Resort_logo.svg/135px-Disneyland_Resort_logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/20px-Animation_disc.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/6/69/P_vip.svg/19px-P_vip.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Magic_Kingdom_castle.jpg/15px-Magic_Kingdom_castle.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/e/e7/Video-x-generic.svg/19px-Video-x-generic.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Flag_of_Los_Angeles_County%2C_California.svg/21px-Flag_of_Los_Angeles_County%2C_California.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Blank_television_set.svg/21px-Blank_television_set.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/21px-Flag_of_the_United_States.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/14px-Commons-logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/16px-Wikiquote-logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Wikidata-logo.svg/21px-Wikidata-logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " '//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1',\n",
       " '/static/images/footer/wikimedia-button.png',\n",
       " '/static/images/footer/poweredby_mediawiki_88x31.png']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "response=requests.get(url)\n",
    "\n",
    "soup=BeautifulSoup(response.content)\n",
    "\n",
    "url_list=[]\n",
    "\n",
    "for element in soup.find_all(\"img\"):\n",
    "    url_list.append(element[\"src\"])\n",
    "\n",
    "url_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. List all language names and number of related articles in the order they appear in wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'English — Wikipedia — The Free Encyclopedia': '6 458 000',\n",
       " 'Nihongo — ウィキペディア — フリー百科事典': '1 314 000',\n",
       " 'Russkiy — Википедия — Свободная энциклопедия': '1 798 000',\n",
       " 'Español — Wikipedia — La enciclopedia libre': '1 755 000',\n",
       " 'Deutsch — Wikipedia — Die freie Enzyklopädie': '2 667 000',\n",
       " 'français — Wikipédia — L’encyclopédie libre': '2 400 000',\n",
       " \"Italiano — Wikipedia — L'enciclopedia libera\": '1 742 000',\n",
       " 'Zhōngwén — 维基百科 / 維基百科 — 自由的百科全书 / 自由的百科全書': '1 256 000',\n",
       " 'Português — Wikipédia — A enciclopédia livre': '1 085 000',\n",
       " 'Al-ʿArabīyah — ويكيبيديا — الموسوعة الحرة': '1 159 000'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "response=requests.get(url)\n",
    "\n",
    "soup1=BeautifulSoup(response.content)\n",
    "\n",
    "soup2=soup1.find_all(\"div\",attrs={\"class\":\"central-featured\"})\n",
    "\n",
    "soup3=soup2[0]\n",
    "\n",
    "soup4=soup3.find_all(\"a\")\n",
    "\n",
    "titulo=[]\n",
    "articles=[]\n",
    "\n",
    "for element in soup4:\n",
    "    titulo.append((element[\"title\"]))\n",
    "\n",
    "for element in soup4:\n",
    "    articles.append(\" \".join(re.findall(\"\\d+\",element.small.text)))\n",
    "\n",
    "\n",
    "dict(zip(titulo, articles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Display the top 10 languages by number of native speakers stored in a pandas dataframe.\n",
    "Hint: After finding the correct table you want to analyse, you can use a nested **for** loop to find the elements row by row (check out the 'td' and 'tr' tags). <br>An easier way to do it is using pd.read_html(), check out documentation [here](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.read_html.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mandarin Chinese': '929.0',\n",
       " 'Spanish': '474.7',\n",
       " 'English': '372.9',\n",
       " 'Hindi (Sanskritised Hindustani)[11]': '343.9',\n",
       " 'Bengali': '233.7',\n",
       " 'Portuguese': '232.4',\n",
       " 'Russian': '154.0',\n",
       " 'Japanese': '125.3',\n",
       " 'Western Punjabi[12]': '92.7',\n",
       " 'Yue Chinese': '85.2',\n",
       " 'Vietnamese': '84.6',\n",
       " 'Marathi': '83.1',\n",
       " 'Telugu': '82.0',\n",
       " 'Turkish': '82.2',\n",
       " 'Wu Chinese': '81.7',\n",
       " 'Korean': '81.7',\n",
       " 'French': '79.9',\n",
       " 'German (only Standard German)': '75.6',\n",
       " 'Tamil': '75.0',\n",
       " 'Urdu (Persianised Hindustani)[11]': '70.2',\n",
       " 'Javanese': '68.3',\n",
       " 'Italian': '64.8',\n",
       " 'Egyptian Arabic': '64.6',\n",
       " 'Gujarati': '57.0',\n",
       " 'Iranian Persian': '56.4',\n",
       " 'Bhojpuri': '52.2',\n",
       " 'Southern Min': '50.1',\n",
       " 'Hakka': '48.2',\n",
       " 'Jin Chinese': '46.9',\n",
       " 'Hausa': '43.9',\n",
       " 'Kannada': '43.6',\n",
       " 'Indonesian': '43.6[a]',\n",
       " 'Yoruba': '43.6',\n",
       " 'Polish': '40.0',\n",
       " 'Xiang Chinese': '37.3',\n",
       " 'Malayalam': '37.1',\n",
       " 'Odia': '34.5',\n",
       " 'Maithili': '33.9',\n",
       " 'Sudanese Arabic': '33.3',\n",
       " 'Burmese': '33.0',\n",
       " 'Eastern Punjabi[12]': '32.6',\n",
       " 'Sunda': '32.4',\n",
       " 'Algerian Arabic': '34.7',\n",
       " 'Moroccan Arabic': '27.5',\n",
       " 'Ukrainian': '27.3',\n",
       " 'Igbo': '27.0',\n",
       " 'Northern Uzbek': '25.1',\n",
       " 'Sindhi': '24.6',\n",
       " 'North Levantine Arabic': '24.6',\n",
       " 'Romanian': '24.3',\n",
       " 'Tagalog': '23.6',\n",
       " 'Dutch': '23.1',\n",
       " 'Saʽidi Arabic': '22.4',\n",
       " 'Gan Chinese': '22.1',\n",
       " 'Amharic': '21.9',\n",
       " 'Northern Pashto': '20.9',\n",
       " 'Magahi': '20.7',\n",
       " 'Thai': '20.7',\n",
       " 'Saraiki': '20.0',\n",
       " 'Khmer': '16.6',\n",
       " 'Chhattisgarhi': '16.3',\n",
       " 'Somali': '16.2',\n",
       " 'Malaysian (Malaysian Malay)': '16.1',\n",
       " 'Cebuano': '15.9',\n",
       " 'Nepali': '15.8',\n",
       " 'Mesopotamian Arabic': '15.7',\n",
       " 'Assamese': '15.3',\n",
       " 'Sinhalese': '15.3',\n",
       " 'Northern Kurdish': '14.6',\n",
       " 'Hejazi Arabic': '14.5',\n",
       " 'Nigerian Fulfulde': '14.5',\n",
       " 'Bavarian': '14.1',\n",
       " 'South Azerbaijani': '13.8',\n",
       " 'Greek': '13.1',\n",
       " 'Chittagonian': '13.0',\n",
       " 'Kazakh': '12.9',\n",
       " 'Deccan': '12.8',\n",
       " 'Hungarian': '12.6',\n",
       " 'Kinyarwanda': '12.1',\n",
       " 'Zulu': '12.1',\n",
       " 'South Levantine Arabic': '11.6',\n",
       " 'Tunisian Arabic': '11.6',\n",
       " 'Sanaani Spoken Arabic': '11.4',\n",
       " 'Northern Min': '11.0',\n",
       " 'Southern Pashto': '10.9',\n",
       " 'Rundi': '10.8',\n",
       " 'Czech': '10.7',\n",
       " 'Taʽizzi-Adeni Arabic': '10.5',\n",
       " 'Uyghur': '10.4',\n",
       " 'Eastern Min': '10.3',\n",
       " 'Sylheti': '10.3'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "response=requests.get(url)\n",
    "\n",
    "soup=BeautifulSoup(response.content)\n",
    "\n",
    "soup2=soup.find_all(\"div\",attrs={\"id\":\"mw-content-text\"})\n",
    "\n",
    "soup3=soup2[0].find_all(\"tbody\")[0].find_all(\"tr\")\n",
    "\n",
    "soup3[1].text.split(\"\\n\")\n",
    "\n",
    "soup3[2].text.split(\"\\n\")\n",
    "\n",
    "languages=[]\n",
    "speakers=[]\n",
    "\n",
    "\n",
    "for i in range(1,len(soup3)):\n",
    "    languages.append(soup3[i].text.split(\"\\n\")[3])\n",
    "    speakers.append(soup3[i].text.split(\"\\n\")[5])\n",
    "\n",
    "\n",
    "dict(zip(languages,speakers))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Display IMDB's top 250 data (movie name, initial release, director name and stars) as a pandas dataframe.\n",
    "Hint: If you hover over the title of the movie, you should see the director's name. Can you find where it's stored in the html?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Os Condenados de Shawshank': 'Frank Darabont ',\n",
       " 'O Padrinho': 'Francis Ford Coppola ',\n",
       " 'O Cavaleiro das Trevas': 'Christopher Nolan ',\n",
       " 'O Padrinho: Parte II': 'Francis Ford Coppola ',\n",
       " 'Doze Homens em Fúria': 'Sidney Lumet ',\n",
       " 'A Lista de Schindler': 'Steven Spielberg ',\n",
       " 'O Senhor dos Anéis - O Regresso do Rei': 'Peter Jackson ',\n",
       " 'Pulp Fiction': 'Quentin Tarantino ',\n",
       " 'O Senhor dos Anéis - A Irmandade do Anel': 'Peter Jackson ',\n",
       " 'O Bom, o Mau e o Vilão': 'Sergio Leone ',\n",
       " 'Forrest Gump': 'Robert Zemeckis ',\n",
       " 'Clube de Combate': 'David Fincher ',\n",
       " 'A Origem': 'Christopher Nolan ',\n",
       " 'O Senhor dos Anéis - As Duas Torres': 'Peter Jackson ',\n",
       " 'Star Wars: Episódio V - O Império Contra-Ataca': 'Irvin Kershner ',\n",
       " 'Matrix': 'Lana Wachowski ',\n",
       " 'Tudo Bons Rapazes': 'Martin Scorsese ',\n",
       " 'Voando Sobre Um Ninho de Cucos': 'Milos Forman ',\n",
       " 'Seven - 7 Pecados Mortais': 'David Fincher ',\n",
       " 'Os Sete Samurais': 'Akira Kurosawa ',\n",
       " 'Do Céu Caiu Uma Estrela': 'Frank Capra ',\n",
       " 'O Silêncio dos Inocentes': 'Jonathan Demme ',\n",
       " 'Cidade de Deus': 'Fernando Meirelles ',\n",
       " 'O Resgate do Soldado Ryan': 'Steven Spielberg ',\n",
       " 'A Vida É Bela': 'Roberto Benigni ',\n",
       " 'À Espera de Um Milagre': 'Frank Darabont ',\n",
       " 'Interstellar': 'Christopher Nolan ',\n",
       " 'A Guerra das Estrelas': 'George Lucas ',\n",
       " 'O Exterminador Implacável 2 - O Dia do Julgamento': 'James Cameron ',\n",
       " 'Regresso ao Futuro': 'Robert Zemeckis ',\n",
       " 'A Viagem de Chihiro': 'Hayao Miyazaki ',\n",
       " 'Psico': 'Alfred Hitchcock ',\n",
       " 'O Pianista': 'Roman Polanski ',\n",
       " 'Léon, o Profissional': 'Luc Besson ',\n",
       " 'Parasitas': 'Bong Joon Ho ',\n",
       " 'The Lion King': 'Roger Allers ',\n",
       " 'Gladiador': 'Ridley Scott ',\n",
       " 'América Proibida': 'Tony Kaye ',\n",
       " 'Os Suspeitos do Costume': 'Bryan Singer ',\n",
       " 'The Departed - Entre Inimigos': 'Martin Scorsese ',\n",
       " 'O Terceiro Passo': 'Christopher Nolan ',\n",
       " 'Casablanca': 'Michael Curtiz ',\n",
       " 'Whiplash - Nos Limites': 'Damien Chazelle ',\n",
       " 'Amigos Improváveis': 'Olivier Nakache ',\n",
       " 'Harakiri': 'Masaki Kobayashi ',\n",
       " 'Tempos Modernos': 'Charles Chaplin ',\n",
       " 'O Túmulo dos Pirilampos': 'Isao Takahata ',\n",
       " 'Top Gun: Maverick': 'Joseph Kosinski ',\n",
       " 'Aconteceu no Oeste': 'Sergio Leone ',\n",
       " 'Janela Indiscreta': 'Alfred Hitchcock ',\n",
       " 'Alien - O 8.º Passageiro': 'Ridley Scott ',\n",
       " 'Luzes da Cidade': 'Charles Chaplin ',\n",
       " 'Cinema Paraíso': 'Giuseppe Tornatore ',\n",
       " 'Memento': 'Christopher Nolan ',\n",
       " 'Apocalypse Now': 'Francis Ford Coppola ',\n",
       " 'Os Salteadores da Arca Perdida': 'Steven Spielberg ',\n",
       " 'Django Libertado': 'Quentin Tarantino ',\n",
       " 'WALL·E': 'Andrew Stanton ',\n",
       " 'As Vidas dos Outros': 'Florian Henckel von Donnersmarck ',\n",
       " 'Crepúsculo dos Deuses': 'Billy Wilder ',\n",
       " 'Horizontes de Glória': 'Stanley Kubrick ',\n",
       " 'Shining': 'Stanley Kubrick ',\n",
       " 'O Grande Ditador': 'Charles Chaplin ',\n",
       " 'Testemunha de Acusação': 'Billy Wilder ',\n",
       " 'Vingadores: Guerra do Infinito': 'Anthony Russo ',\n",
       " 'Alien 2 - O Recontro Final': 'James Cameron ',\n",
       " 'Beleza Americana': 'Sam Mendes ',\n",
       " 'Dr. Estranhoamor': 'Stanley Kubrick ',\n",
       " 'Homem-Aranha: No Universo Aranha': 'Bob Persichetti ',\n",
       " 'O Cavaleiro das Trevas Renasce': 'Christopher Nolan ',\n",
       " 'Oldboy-Velho amigo': 'Park Chan',\n",
       " 'Joker': 'Todd Phillips ',\n",
       " 'Amadeus': 'Milos Forman ',\n",
       " 'Braveheart: O Desafio do Guerreiro': 'Mel Gibson ',\n",
       " 'Toy Story: Os Rivais': 'John Lasseter ',\n",
       " 'Coco': 'Lee Unkrich ',\n",
       " 'A Odisseia do Submarino 96': 'Wolfgang Petersen ',\n",
       " 'Sacanas Sem Lei': 'Quentin Tarantino ',\n",
       " 'A Princesa Mononoke': 'Hayao Miyazaki ',\n",
       " 'Vingadores: Endgame': 'Anthony Russo ',\n",
       " 'Era Uma Vez na América': 'Sergio Leone ',\n",
       " 'O Bom Rebelde': 'Gus Van Sant ',\n",
       " 'Toy Story 3': 'Lee Unkrich ',\n",
       " 'A Vida não é um Sonho': 'Darren Aronofsky ',\n",
       " 'Kimi no na wa.': 'Makoto Shinkai ',\n",
       " 'Serenata à Chuva': 'Stanley Donen ',\n",
       " '3 Idiots': 'Rajkumar Hirani ',\n",
       " 'Star Wars: Episódio VI - O Regresso de Jedi': 'Richard Marquand ',\n",
       " '2001: Odisseia no Espaço': 'Stanley Kubrick ',\n",
       " 'O Despertar da Mente': 'Michel Gondry ',\n",
       " 'Cães Danados': 'Quentin Tarantino ',\n",
       " 'Céu e o Inferno': 'Akira Kurosawa ',\n",
       " 'Cafarnaum': 'Nadine Labaki ',\n",
       " 'O Mundo a Seus Pés': 'Orson Welles ',\n",
       " 'Lawrence da Arábia': 'David Lean ',\n",
       " 'The Hunt - A Caça': 'Thomas Vinterberg ',\n",
       " 'Matou': 'Fritz Lang ',\n",
       " 'Intriga Internacional': 'Alfred Hitchcock ',\n",
       " 'A Mulher Que Viveu Duas Vezes': 'Alfred Hitchcock ',\n",
       " 'O Fabuloso Destino de Amélie': 'Jean',\n",
       " 'Vem e Vê': 'Elem Klimov ',\n",
       " 'Laranja Mecânica': 'Stanley Kubrick ',\n",
       " 'Nascido Para Matar': 'Stanley Kubrick ',\n",
       " 'Pagos a Dobrar': 'Billy Wilder ',\n",
       " 'O Apartamento': 'Billy Wilder ',\n",
       " 'Scarface - A Força do Poder': 'Brian De Palma ',\n",
       " 'Viver - Ikiru': 'Akira Kurosawa ',\n",
       " 'A Golpada': 'George Roy Hill ',\n",
       " 'Na Sombra e no Silêncio': 'Robert Mulligan ',\n",
       " 'Taxi Driver': 'Martin Scorsese ',\n",
       " 'Up - Altamente': 'Pete Docter ',\n",
       " 'L.A. Confidencial': 'Curtis Hanson ',\n",
       " 'Heat - Cidade Sob Pressão': 'Michael Mann ',\n",
       " 'Metropolis': 'Fritz Lang ',\n",
       " 'Uma Separação': 'Asghar Farhadi ',\n",
       " 'Incendies - A Mulher que Canta': 'Denis Villeneuve ',\n",
       " 'Die Hard - Assalto ao Arranha-Céus': 'John McTiernan ',\n",
       " 'Snatch - Porcos E Diamantes': 'Guy Ritchie ',\n",
       " 'Hamilton': 'Thomas Kail ',\n",
       " 'Indiana Jones e a Grande Cruzada': 'Steven Spielberg ',\n",
       " 'Ladrões de Bicicletas': 'Vittorio De Sica ',\n",
       " '1917': 'Sam Mendes ',\n",
       " 'Taare Zameen Par': 'Aamir Khan ',\n",
       " 'A Queda: Hitler e o Fim do Terceiro Reich': 'Oliver Hirschbiegel ',\n",
       " 'Por Mais Alguns Dólares': 'Sergio Leone ',\n",
       " 'Batman - O Início': 'Christopher Nolan ',\n",
       " 'Dangal': 'Nitesh Tiwari ',\n",
       " 'O Garoto de Charlot': 'Charles Chaplin ',\n",
       " 'Quanto Mais Quente Melhor': 'Billy Wilder ',\n",
       " 'Homem-Aranha: Sem Volta a Casa': 'Jon Watts ',\n",
       " 'Eva': 'Joseph L',\n",
       " 'O Pai': 'Florian Zeller ',\n",
       " 'Green Book - Um Guia Para a Vida': 'Peter Farrelly ',\n",
       " 'O Lobo de Wall Street': 'Martin Scorsese ',\n",
       " 'O Julgamento de Nuremberga': 'Stanley Kramer ',\n",
       " 'Ran - Os Senhores da Guerra': 'Akira Kurosawa ',\n",
       " 'Imperdoável': 'Clint Eastwood ',\n",
       " 'Casino': 'Martin Scorsese ',\n",
       " 'O Labirinto do Fauno': 'Guillermo del Toro ',\n",
       " 'Haverá Sangue': 'Paul Thomas Anderson ',\n",
       " 'O Sexto Sentido': 'M',\n",
       " 'Uma Mente Brilhante': 'Ron Howard ',\n",
       " 'The Truman Show - A Vida em Directo': 'Peter Weir ',\n",
       " 'Monty Python e o Cálice Sagrado': 'Terry Gilliam ',\n",
       " 'Yojimbo - O Invencível': 'Akira Kurosawa ',\n",
       " 'O Tesouro da Sierra Madre': 'John Huston ',\n",
       " 'Shutter Island': 'Martin Scorsese ',\n",
       " 'Às Portas do Inferno': 'Akira Kurosawa ',\n",
       " 'Parque Jurássico': 'Steven Spielberg ',\n",
       " 'A Grande Evasão': 'John Sturges ',\n",
       " 'Kill Bill - A Vingança (vol. 1)': 'Quentin Tarantino ',\n",
       " 'Este País Não É Para Velhos': 'Ethan Coen ',\n",
       " 'À Procura de Nemo': 'Andrew Stanton ',\n",
       " 'O Homem Elefante': 'David Lynch ',\n",
       " 'Chinatown': 'Roman Polanski ',\n",
       " 'O Touro Enraivecido': 'Martin Scorsese ',\n",
       " 'E Tudo o Vento Levou': 'Victor Fleming ',\n",
       " 'Veio do Outro Mundo': 'John Carpenter ',\n",
       " 'Tudo em Todo o Lado ao Mesmo Tempo': 'Dan Kwan ',\n",
       " 'V de Vingança': 'James McTeigue ',\n",
       " 'Divertida-Mente': 'Pete Docter ',\n",
       " 'Um Mal Nunca Vem Só': 'Guy Ritchie ',\n",
       " 'Chamada para a Morte': 'Alfred Hitchcock ',\n",
       " 'O Segredo dos Seus Olhos': 'Juan Jos',\n",
       " 'O Castelo Andante': 'Hayao Miyazaki ',\n",
       " 'A Ponte do Rio Kwai': 'David Lean ',\n",
       " 'Trainspotting': 'Danny Boyle ',\n",
       " 'Três Cartazes à Beira da Estrada': 'Martin McDonagh ',\n",
       " 'Warrior - Combate Entre Irmãos': 'Gavin O',\n",
       " 'Gran Torino': 'Clint Eastwood ',\n",
       " 'Fargo': 'Joel Coen ',\n",
       " 'Raptadas': 'Denis Villeneuve ',\n",
       " 'O Meu Vizinho Totoro': 'Hayao Miyazaki ',\n",
       " 'Million Dollar Baby - Sonhos Vencidos': 'Clint Eastwood ',\n",
       " 'A Quimera do Ouro': 'Charles Chaplin ',\n",
       " 'Apanha-me Se Puderes': 'Steven Spielberg ',\n",
       " 'Blade Runner - Perigo Iminente': 'Ridley Scott ',\n",
       " 'Há Lodo no Cais': 'Elia Kazan ',\n",
       " 'Bacheha-Ye aseman': 'Majid Majidi ',\n",
       " 'O Terceiro Homem': 'Carol Reed ',\n",
       " 'Ben-Hur': 'William Wyler ',\n",
       " '12 Anos Escravo': 'Steve McQueen ',\n",
       " 'Pamplinas Maquinista': 'Clyde Bruckman ',\n",
       " 'Morangos Silvestres': 'Ingmar Bergman ',\n",
       " 'Antes do Amanhecer': 'Richard Linklater ',\n",
       " 'Em Parte Incerta': 'David Fincher ',\n",
       " 'Harry Potter e os Talismãs da Morte: Parte 2': 'David Yates ',\n",
       " 'O Caçador': 'Michael Cimino ',\n",
       " 'Em Nome do Pai': 'Jim Sheridan ',\n",
       " 'Grand Budapest Hotel': 'Wes Anderson ',\n",
       " 'Peço a Palavra': 'Frank Capra ',\n",
       " 'O Salário do Medo': 'Henri',\n",
       " 'Barry Lyndon': 'Stanley Kubrick ',\n",
       " 'Sherlock Holmes Jr.': 'Buster Keaton ',\n",
       " 'Memórias de Um Assassino': 'Bong Joon Ho ',\n",
       " 'Klaus': 'Sergio Pablos ',\n",
       " 'O Herói de Hacksaw Ridge': 'Mel Gibson ',\n",
       " 'O Sétimo Selo': 'Ingmar Bergman ',\n",
       " 'Quarto': 'Lenny Abrahamson ',\n",
       " 'Relatos Selvagens': 'Dami',\n",
       " 'Mad Max: A Estrada da Morte': 'George Miller ',\n",
       " 'O Grande Lebowski': 'Joel Coen ',\n",
       " 'Como Treinares o Teu Dragão': 'Dean DeBlois ',\n",
       " 'Mary and Max.': 'Adam Elliot ',\n",
       " 'Monstros e Companhia': 'Pete Docter ',\n",
       " 'Tubarão': 'Steven Spielberg ',\n",
       " \"A Paixão de Joana d'Arc\": 'Carl Theodor Dreyer ',\n",
       " 'Viagem a Tóquio': 'Yasujir',\n",
       " 'O Clube dos Poetas Mortos': 'Peter Weir ',\n",
       " 'Hotel Ruanda': 'Terry George ',\n",
       " 'Rocky': 'John G',\n",
       " 'Platoon - Os Bravos do Pelotão': 'Oliver Stone ',\n",
       " \"Le Mans '66: O Duelo\": 'James Mangold ',\n",
       " 'O Lamento da Vereda': 'Satyajit Ray ',\n",
       " 'Conta Comigo': 'Rob Reiner ',\n",
       " 'O Exterminador Implacável': 'James Cameron ',\n",
       " 'O Caso Spotlight': 'Tom McCarthy ',\n",
       " 'Rush - Duelo de Rivais': 'Ron Howard ',\n",
       " 'Escândalo na TV': 'Sidney Lumet ',\n",
       " 'O Lado Selvagem': 'Sean Penn ',\n",
       " 'Logan': 'James Mangold ',\n",
       " 'O Feiticeiro de Oz': 'Victor Fleming ',\n",
       " 'Ratatui': 'Brad Bird ',\n",
       " 'O Feitiço do Tempo': 'Harold Ramis ',\n",
       " 'Antes do Anoitecer': 'Richard Linklater ',\n",
       " 'O Exorcista': 'William Friedkin ',\n",
       " 'Os Melhores Anos das Nossas Vidas': 'William Wyler ',\n",
       " 'The Incredibles - Os Super Heróis': 'Brad Bird ',\n",
       " 'Ser ou Não Ser': 'Ernst Lubitsch ',\n",
       " 'As Vinhas da Ira': 'John Ford ',\n",
       " 'Rebecca': 'Alfred Hitchcock ',\n",
       " 'A Batalha de Argel': 'Gillo Pontecorvo ',\n",
       " 'Hachiko - Amigo para Sempre': 'Lasse Hallstr',\n",
       " 'O Presidiário': 'Stuart Rosenberg ',\n",
       " 'Amor Cão': 'Alejandro G',\n",
       " 'Piratas das Caraíbas - A Maldição do Pérola Negra': 'Gore Verbinski ',\n",
       " 'O Ódio': 'Mathieu Kassovitz ',\n",
       " 'Os Quatrocentos Golpes': 'Fran',\n",
       " 'A Máscara': 'Ingmar Bergman ',\n",
       " 'Babam ve Oglum': 'Cagan Irmak ',\n",
       " 'Uma Noite Aconteceu': 'Frank Capra ',\n",
       " 'A Vida de Brian': 'Terry Jones ',\n",
       " 'Música no Coração': 'Robert Wise ',\n",
       " 'Dersu Uzala - A Águia da Estepe': 'Akira Kurosawa ',\n",
       " 'A Criada': 'Park Chan',\n",
       " 'Gandhi': 'Richard Attenborough ',\n",
       " 'Aladdin': 'Ron Clements ',\n",
       " 'As Serviçais': 'Tate Taylor ',\n",
       " 'Jai Bhim': 'T',\n",
       " 'A Bela e o Monstro': 'Gary Trousdale '}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "r=requests.get('https://www.imdb.com/chart/top')\n",
    "\n",
    "soup=BeautifulSoup(r.content)\n",
    "\n",
    "soup=soup.find_all(\"td\",{\"class\":\"titleColumn\"})\n",
    "\n",
    "title=[]\n",
    "director=[]\n",
    "\n",
    "for element in soup:\n",
    "\n",
    "    title.append(element.a.text)\n",
    "    director.append(re.findall(\"[A-Z a-z]*\",element.a[\"title\"])[0])\n",
    "\n",
    "\n",
    "dict(zip(title,director))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Display the movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'https://www.imdb.com/list/ls009796553/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pesadelo em Elm Street</td>\n",
       "      <td>Teenager Nancy Thompson must uncover the dark ...</td>\n",
       "      <td>(1984)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Despertares</td>\n",
       "      <td>The victims of an encephalitis epidemic many y...</td>\n",
       "      <td>(1990)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Liga de Mulheres</td>\n",
       "      <td>Two sisters join the first female professional...</td>\n",
       "      <td>(1992)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Um Bairro em Nova Iorque</td>\n",
       "      <td>A father becomes worried when a local gangster...</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anjos em Campo</td>\n",
       "      <td>When a boy prays for a chance to have a family...</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tempo de Matar</td>\n",
       "      <td>In Canton, Mississippi, a fearless young lawye...</td>\n",
       "      <td>(1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amistad</td>\n",
       "      <td>In 1839, the revolt of Mende captives aboard a...</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Anaconda</td>\n",
       "      <td>A \"National Geographic\" film crew is taken hos...</td>\n",
       "      <td>(1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A Cool, Dry Place</td>\n",
       "      <td>Russell, single father balances his work as a ...</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>América Proibida</td>\n",
       "      <td>A former neo-nazi skinhead tries to prevent hi...</td>\n",
       "      <td>(1998)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Titles  \\\n",
       "0    Pesadelo em Elm Street   \n",
       "1               Despertares   \n",
       "2          Liga de Mulheres   \n",
       "3  Um Bairro em Nova Iorque   \n",
       "4            Anjos em Campo   \n",
       "5            Tempo de Matar   \n",
       "6                   Amistad   \n",
       "7                  Anaconda   \n",
       "8         A Cool, Dry Place   \n",
       "9          América Proibida   \n",
       "\n",
       "                                             Summary    Year  \n",
       "0  Teenager Nancy Thompson must uncover the dark ...  (1984)  \n",
       "1  The victims of an encephalitis epidemic many y...  (1990)  \n",
       "2  Two sisters join the first female professional...  (1992)  \n",
       "3  A father becomes worried when a local gangster...  (1993)  \n",
       "4  When a boy prays for a chance to have a family...  (1994)  \n",
       "5  In Canton, Mississippi, a fearless young lawye...  (1996)  \n",
       "6  In 1839, the revolt of Mende captives aboard a...  (1997)  \n",
       "7  A \"National Geographic\" film crew is taken hos...  (1997)  \n",
       "8  Russell, single father balances his work as a ...  (1998)  \n",
       "9  A former neo-nazi skinhead tries to prevent hi...  (1998)  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "response=requests.get('https://www.imdb.com/list/ls009796553/')\n",
    "\n",
    "soup=BeautifulSoup(response.content)\n",
    "\n",
    "soup=soup.find_all(\"div\",attrs={\"class\":\"article listo\"})\n",
    "\n",
    "title=soup[0].find_all(\"h3\",attrs={\"class\":\"lister-item-header\"}) #titulo\n",
    "\n",
    "year=soup[0].find_all(\"span\",attrs={\"class\":\"lister-item-year text-muted unbold\"})\n",
    "\n",
    "summary=soup[0].find_all(\"p\",attrs={\"class\":\"\"})\n",
    "\n",
    "titles=[]\n",
    "years=[]\n",
    "summaries=[]\n",
    "\n",
    "for element in title:\n",
    "    titles.append(element.a.text)\n",
    "\n",
    "for element in year:\n",
    "    years.append(element.text)\n",
    "\n",
    "for element in summary:\n",
    "    summaries.append(element.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "\n",
    "d={}\n",
    "d[\"Titles\"]=titles[0:10]\n",
    "d[\"Summary\"]=summaries[0:10]\n",
    "d[\"Year\"]=years[0:10]\n",
    "\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = input('Enter the city: ')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the book name, price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titles</th>\n",
       "      <th>prices</th>\n",
       "      <th>availabilty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>£51.77</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>£53.74</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>£50.10</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>£47.82</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>£54.23</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Requiem Red</td>\n",
       "      <td>£22.65</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Dirty Little Secrets of Getting Your Dream...</td>\n",
       "      <td>£33.34</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Coming Woman: A Novel Based on the Life of...</td>\n",
       "      <td>£17.93</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Boys in the Boat: Nine Americans and Their...</td>\n",
       "      <td>£22.60</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Black Maria</td>\n",
       "      <td>£52.15</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Starving Hearts (Triangular Trade Trilogy, #1)</td>\n",
       "      <td>£13.99</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shakespeare's Sonnets</td>\n",
       "      <td>£20.66</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Set Me Free</td>\n",
       "      <td>£17.46</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Scott Pilgrim's Precious Little Life (Scott Pi...</td>\n",
       "      <td>£52.29</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Rip it Up and Start Again</td>\n",
       "      <td>£35.02</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Our Band Could Be Your Life: Scenes from the A...</td>\n",
       "      <td>£57.25</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Olio</td>\n",
       "      <td>£23.88</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mesaerion: The Best Science Fiction Stories 18...</td>\n",
       "      <td>£37.59</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Libertarianism for Beginners</td>\n",
       "      <td>£51.33</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>It's Only the Himalayas</td>\n",
       "      <td>£45.17</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               titles  prices availabilty\n",
       "0                                A Light in the Attic  £51.77    In stock\n",
       "1                                  Tipping the Velvet  £53.74    In stock\n",
       "2                                          Soumission  £50.10    In stock\n",
       "3                                       Sharp Objects  £47.82    In stock\n",
       "4               Sapiens: A Brief History of Humankind  £54.23    In stock\n",
       "5                                     The Requiem Red  £22.65    In stock\n",
       "6   The Dirty Little Secrets of Getting Your Dream...  £33.34    In stock\n",
       "7   The Coming Woman: A Novel Based on the Life of...  £17.93    In stock\n",
       "8   The Boys in the Boat: Nine Americans and Their...  £22.60    In stock\n",
       "9                                     The Black Maria  £52.15    In stock\n",
       "10     Starving Hearts (Triangular Trade Trilogy, #1)  £13.99    In stock\n",
       "11                              Shakespeare's Sonnets  £20.66    In stock\n",
       "12                                        Set Me Free  £17.46    In stock\n",
       "13  Scott Pilgrim's Precious Little Life (Scott Pi...  £52.29    In stock\n",
       "14                          Rip it Up and Start Again  £35.02    In stock\n",
       "15  Our Band Could Be Your Life: Scenes from the A...  £57.25    In stock\n",
       "16                                               Olio  £23.88    In stock\n",
       "17  Mesaerion: The Best Science Fiction Stories 18...  £37.59    In stock\n",
       "18                       Libertarianism for Beginners  £51.33    In stock\n",
       "19                            It's Only the Himalayas  £45.17    In stock"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "response=requests.get(url)\n",
    "\n",
    "soup=BeautifulSoup(response.content)\n",
    "\n",
    "soup=soup.find_all(\"article\",attrs={\"class\":\"product_pod\"})\n",
    "\n",
    "titles=[]\n",
    "prices=[]\n",
    "stocks=[]\n",
    "\n",
    "for element in soup:\n",
    "\n",
    "    titles.append(element.find_all(\"a\")[1][\"title\"]) # title\n",
    "\n",
    "    prices.append(element.find_all(\"p\",attrs={\"class\":\"price_color\"})[0].text) #price\n",
    "\n",
    "    stocks.append(element.find_all(\"p\",attrs={\"class\":\"instock availability\"})[0].text.strip()) #availability\n",
    "\n",
    "\n",
    "d={}\n",
    "\n",
    "\n",
    "d[\"titles\"]=titles\n",
    "d[\"prices\"]=prices\n",
    "d[\"availabilty\"]=stocks\n",
    "\n",
    "pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Display the 100 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe.\n",
    "***Hint:*** Here the displayed number of earthquakes per page is 20, but you can easily move to the next page by looping through the desired number of pages and adding it to the end of the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.emsc-csem.org/Earthquake/?view=1',\n",
       " 'https://www.emsc-csem.org/Earthquake/?view=2',\n",
       " 'https://www.emsc-csem.org/Earthquake/?view=3',\n",
       " 'https://www.emsc-csem.org/Earthquake/?view=4',\n",
       " 'https://www.emsc-csem.org/Earthquake/?view=5']"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/?view='\n",
    "\n",
    "# This is how you will loop through each page:\n",
    "number_of_pages = int(100/20)\n",
    "each_page_urls = []\n",
    "\n",
    "for n in range(1, number_of_pages+1):\n",
    "    link = url+str(n)\n",
    "    each_page_urls.append(link)\n",
    "    \n",
    "each_page_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.emsc-csem.org/Earthquake/?view='\n",
    "\n",
    "response=requests.get(url)\n",
    "\n",
    "soup=BeautifulSoup(response.content).find_all(\"tbody\",attrs={\"id\":\"tbody\"})\n",
    "\n",
    "soup=soup[0]\n",
    "\n",
    "time_date=soup.find_all(\"td\",attrs={\"class\":\"tabev6\"})\n",
    "lat_long=soup.find_all(\"td\",attrs={\"class\":\"tabev1\"})\n",
    "lat=lat_long[0::2]\n",
    "long=lat_long[1::2]\n",
    "region=soup.find_all(\"td\",{\"class\":\"tb_region\"})\n",
    "\n",
    "dates=[]\n",
    "times=[]\n",
    "regions=[]\n",
    "lats=[]\n",
    "longs=[]\n",
    "\n",
    "for element in time_date:\n",
    "    dates.append(re.findall(\"\\d+-\\d+-\\d+\",element.text))\n",
    "    times.append(re.findall(\"\\d+:\\d+:\\d+\",element.text))\n",
    "\n",
    "for element in long:\n",
    "    longs.append(element.text.strip())\n",
    "\n",
    "for element in lat:\n",
    "    lats.append(element.text.strip())\n",
    "\n",
    "for element in region:\n",
    "    regions.append(element.text.strip())\n",
    "\n",
    "\n",
    "d={}\n",
    "\n",
    "d[\"Date\"]=dates\n",
    "d[\"Time\"]=times\n",
    "d[\"Region Name\"]=regions\n",
    "d[\"Latitutde\"]=lats\n",
    "d[\"Longitude\"]=longs\n",
    "\n",
    "d=pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.emsc-csem.org/Earthquake/?view=2'\n",
    "\n",
    "response=requests.get(url)\n",
    "\n",
    "soup=BeautifulSoup(response.content).find_all(\"tbody\",attrs={\"id\":\"tbody\"})\n",
    "\n",
    "soup=soup[0]\n",
    "\n",
    "time_date=soup.find_all(\"td\",attrs={\"class\":\"tabev6\"})\n",
    "lat_long=soup.find_all(\"td\",attrs={\"class\":\"tabev1\"})\n",
    "lat=lat_long[0::2]\n",
    "long=lat_long[1::2]\n",
    "region=soup.find_all(\"td\",{\"class\":\"tb_region\"})\n",
    "\n",
    "dates=[]\n",
    "times=[]\n",
    "regions=[]\n",
    "lats=[]\n",
    "longs=[]\n",
    "\n",
    "for element in time_date:\n",
    "    dates.append(re.findall(\"\\d+-\\d+-\\d+\",element.text))\n",
    "    times.append(re.findall(\"\\d+:\\d+:\\d+\",element.text))\n",
    "\n",
    "for element in long:\n",
    "    longs.append(element.text.strip())\n",
    "\n",
    "for element in lat:\n",
    "    lats.append(element.text.strip())\n",
    "\n",
    "for element in region:\n",
    "    regions.append(element.text.strip())\n",
    "\n",
    "\n",
    "d2={}\n",
    "\n",
    "d2[\"Date\"]=dates\n",
    "d2[\"Time\"]=times\n",
    "d2[\"Region Name\"]=regions\n",
    "d2[\"Latitutde\"]=lats\n",
    "d2[\"Longitude\"]=longs\n",
    "\n",
    "d2=pd.DataFrame(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Region Name</th>\n",
       "      <th>Latitutde</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2022-07-23]</td>\n",
       "      <td>[10:52:24]</td>\n",
       "      <td>TARAPACA, CHILE</td>\n",
       "      <td>20.91</td>\n",
       "      <td>69.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2022-07-23]</td>\n",
       "      <td>[10:51:03]</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>7.64</td>\n",
       "      <td>81.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2022-07-23]</td>\n",
       "      <td>[10:36:03]</td>\n",
       "      <td>GULF OF ALASKA</td>\n",
       "      <td>56.29</td>\n",
       "      <td>149.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2022-07-23]</td>\n",
       "      <td>[10:17:48]</td>\n",
       "      <td>SLOVENIA</td>\n",
       "      <td>46.49</td>\n",
       "      <td>14.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2022-07-23]</td>\n",
       "      <td>[10:13:10]</td>\n",
       "      <td>STRAIT OF GIBRALTAR</td>\n",
       "      <td>35.45</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[2022-07-22]</td>\n",
       "      <td>[23:04:27]</td>\n",
       "      <td>KEPULAUAN ALOR, INDONESIA</td>\n",
       "      <td>8.95</td>\n",
       "      <td>124.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[2022-07-22]</td>\n",
       "      <td>[23:02:09]</td>\n",
       "      <td>OFFSHORE COQUIMBO, CHILE</td>\n",
       "      <td>31.49</td>\n",
       "      <td>71.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[2022-07-22]</td>\n",
       "      <td>[22:51:34]</td>\n",
       "      <td>OFFSHORE EL SALVADOR</td>\n",
       "      <td>12.80</td>\n",
       "      <td>88.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[2022-07-22]</td>\n",
       "      <td>[22:46:40]</td>\n",
       "      <td>TARAPACA, CHILE</td>\n",
       "      <td>20.35</td>\n",
       "      <td>69.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[2022-07-22]</td>\n",
       "      <td>[22:46:27]</td>\n",
       "      <td>COLOMBIA-ECUADOR BORDER REGION</td>\n",
       "      <td>0.86</td>\n",
       "      <td>77.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Time                     Region Name Latitutde  \\\n",
       "0   [2022-07-23]  [10:52:24]                 TARAPACA, CHILE     20.91   \n",
       "1   [2022-07-23]  [10:51:03]                          PANAMA      7.64   \n",
       "2   [2022-07-23]  [10:36:03]                  GULF OF ALASKA     56.29   \n",
       "3   [2022-07-23]  [10:17:48]                        SLOVENIA     46.49   \n",
       "4   [2022-07-23]  [10:13:10]             STRAIT OF GIBRALTAR     35.45   \n",
       "..           ...         ...                             ...       ...   \n",
       "46  [2022-07-22]  [23:04:27]       KEPULAUAN ALOR, INDONESIA      8.95   \n",
       "47  [2022-07-22]  [23:02:09]        OFFSHORE COQUIMBO, CHILE     31.49   \n",
       "48  [2022-07-22]  [22:51:34]            OFFSHORE EL SALVADOR     12.80   \n",
       "49  [2022-07-22]  [22:46:40]                 TARAPACA, CHILE     20.35   \n",
       "50  [2022-07-22]  [22:46:27]  COLOMBIA-ECUADOR BORDER REGION      0.86   \n",
       "\n",
       "   Longitude  \n",
       "0      69.44  \n",
       "1      81.29  \n",
       "2     149.20  \n",
       "3      14.99  \n",
       "4       3.57  \n",
       "..       ...  \n",
       "46    124.26  \n",
       "47     71.74  \n",
       "48     88.65  \n",
       "49     69.25  \n",
       "50     77.96  \n",
       "\n",
       "[101 rows x 5 columns]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquakes=pd.concat([d,d2])\n",
    "\n",
    "earthquakes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
